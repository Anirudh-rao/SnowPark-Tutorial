{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "oscdbhgsu24gx5fhl5pq",
   "authorId": "2857618133917",
   "authorName": "ROOK",
   "authorEmail": "anirudh.rao@gds.ey.com",
   "sessionId": "63b098ff-6c51-4033-961b-fc7b01bc2cd6",
   "lastEditTime": 1754389559933
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e9c782-170b-4ede-b8d2-12ec8380a1c5",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "# Snowpark Machine Learning\n\nIn this section we will cover topics related to:\n\n1. Outline Snowpark Architecture:\n\n    Types of Libraries used for Machine Learning\n\n2. Operationalize snowpark stored procedures\n\n    Use Snowpark Python Stored Procedures in run workloads\n\nFollow the below link for more information:\n\n[Getting Started with ML Development in Snowflake](https://quickstarts.snowflake.com/guide/intro_to_machine_learning_with_snowpark_ml_for_python/#0)"
  },
  {
   "cell_type": "code",
   "id": "c7c9ebd1-68ca-4f81-b70c-c9071d09053b",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "#Gettng Libraries:\nimport numpy as np\nfrom snowflake.ml.modeling.preprocessing import *\nfrom snowflake.snowpark.types import *\nfrom snowflake.snowpark.functions import *\nfrom snowflake.ml.modeling.pipeline import Pipeline\nfrom snowflake.ml.modeling.xgboost import XGBRegressor\nfrom snowflake.ml.registry import Registry\nfrom snowflake.snowpark.context import get_active_session",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3280cbc0-cb0a-4dc4-8aa6-b0c021d6be08",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "#Creating Session:\nsession =  get_active_session()\nsession.query_tag = 'ml-example'",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "71c99586-5540-4244-bbc1-e24692121b77",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "df = session.table('snowpark_db.works.diamonds')\ndf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "58837b74-d8d8-4b45-a061-73ea577a8c9b",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "# data clearning \nfor colname in df.columns:\n    df = df.with_column_renamed(colname, str.upper(colname))\ndf = df.with_column(\"CUT\", upper(regexp_replace(\"CUT\", '[^a-zA-Z0-9]+', '_')))\nfor colname in [\"CARAT\", \"X\", \"Y\", \"Z\", \"DEPTH\", \"TBL\"]:\n    df = df.with_column(colname, df[colname].cast(DoubleType()))\ndf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2a45c225-5735-4f5d-9ff6-ed02d84017a0",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "#Normalize CARAT Column\nscaler = MinMaxScaler(input_cols=[\"CARAT\"], output_cols=[\"CARAT_NORM\"])\ndf = scaler.fit(df).transform(df)\n\n# Reduce the number of decimals\nnew_col = df.col(\"CARAT_NORM\").cast(DecimalType(7, 6))\ndf = df.with_column(\"CARAT_NORM\", new_col)\ndf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e3e2ecd4-b4d2-4a83-9a98-f75c8d1d693d",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "#Encode CUT and CLARITY Cols\ncategories = {\n    \"CUT\": np.array([\"IDEAL\", \"PREMIUM\", \"VERY_GOOD\", \"GOOD\", \"FAIR\"]),\n    \"CLARITY\": np.array([\"IF\", \"VVS1\", \"VVS2\", \"VS1\", \"VS2\", \"SI1\", \"SI2\", \"I1\", \"I2\", \"I3\"]),\n}\nencoder = OrdinalEncoder(\n    input_cols=[\"CUT\", \"CLARITY\"],\n    output_cols=[\"CUT_OE\", \"CLARITY_OE\"],\n    categories=categories)\ndf = encoder.fit(df).transform(df)\nprint(encoder._state_pandas)\ndf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "27017c36-8d46-4fc0-b80e-cf381bbbc15a",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "#Encode Categorical to Numeric Columns\nencoder = OneHotEncoder(\n    input_cols=[\"CUT\", \"COLOR\", \"CLARITY\"],\n    output_cols=[\"CUT_OHE\", \"COLOR_OHE\", \"CLARITY_OHE\"])\ndf = encoder.fit(df).transform(df)\nnp.array(df.columns)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7d87fc65-2f47-472a-b718-2665e3701433",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "#Build Pipeline\nCATEGORICAL_COLUMNS = [\"CUT\", \"COLOR\", \"CLARITY\"]\nCATEGORICAL_COLUMNS_OE = [\"CUT_OE\", \"COLOR_OE\", \"CLARITY_OE\"]\nNUMERICAL_COLUMNS = [\"CARAT\", \"DEPTH\", \"TBL\", \"X\", \"Y\", \"Z\"]\n\ncategories = {\n    \"CUT\": np.array([\"IDEAL\", \"PREMIUM\", \"VERY_GOOD\", \"GOOD\", \"FAIR\"]),\n    \"CLARITY\": np.array([\"IF\", \"VVS1\", \"VVS2\", \"VS1\", \"VS2\", \"SI1\", \"SI2\", \"I1\", \"I2\", \"I3\"]),\n    \"COLOR\": np.array(['D', 'E', 'F', 'G', 'H', 'I', 'J']),\n}\n\npipeline = Pipeline(steps=[(\n        \"OE\", OrdinalEncoder(\n            input_cols=CATEGORICAL_COLUMNS,\n            output_cols=CATEGORICAL_COLUMNS_OE,\n            categories=categories,\n        )\n    ),(\n        \"MMS\", MinMaxScaler(\n            clip=True,\n            input_cols=NUMERICAL_COLUMNS,\n            output_cols=NUMERICAL_COLUMNS,\n        )\n    )])\ndf = pipeline.fit(df).transform(df)\ndf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "54c47068-1455-43b5-afae-b04016d5ebed",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "# split and run the train and test sets through the pipeline\ntrain_df, test_df = df.random_split(weights=[0.9, 0.1], seed=0)\n\ntrain_df = pipeline.fit(train_df).transform(train_df)\ntest_df = pipeline.transform(test_df)\ntest_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "30ae20d4-cb41-447b-9e0a-e7d159d9153b",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": "# train model with an XGBoost regressor + make a prediction\nregressor = XGBRegressor(\n    input_cols=CATEGORICAL_COLUMNS_OE+NUMERICAL_COLUMNS,\n    label_cols=['PRICE'],\n    output_cols=['PREDICTED_PRICE'])\nregressor.fit(train_df)\ndf = regressor.predict(test_df)\ndf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3264d197-fd33-4bb3-9c5c-f965f017ccf4",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "# log the model in the internal registry\nreg = Registry(session=session, database_name=\"SNOWPARK_DB\", schema_name=\"WORKS\")\n#model = reg.delete_model(\"DIAMONDS_PRICE_PREDICTION\")\nmodel = reg.log_model(\n    model_name=\"DIAMONDS_PRICE_PREDICTION\",\n    version_name='V0',\n    model=regressor,\n    options={'relax_version': True})\nreg.get_model(\"DIAMONDS_PRICE_PREDICTION\").show_versions()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "08f8ee35-c08a-4d3a-8da1-7414554b1c2b",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": "# get the model and run some predictions using the test data\nmodel = reg.get_model(\"DIAMONDS_PRICE_PREDICTION\").version('V0')\ndf = model.run(test_df, function_name=\"predict\")\ndf",
   "execution_count": null
  }
 ]
}